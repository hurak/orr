---
title: "Course outline"
format:
    html     
---

The course is structured into 14 topics, each of them corresponding to one lecture. The topics are as follows:

- Optimization (recap/overview)
    1. Theory: formulations, conditions, types of problems, optimization modellers, ...
       Algorithms: computing derivatives (symbolic, finite difference, autdiff),  gradient, Newton, ..., solvers 
- Discrete-time optimal control
    2. Direct approach (via optimization): on a finite horizon, on a receding horizon (aka MPC)
    3. Indirect approach (via Hamilton equations): finite and infinite horizon, LQR, Riccati equations, ...
    4. Dynamic programming: Bellman's principle, ...
    5. More on MPC: combining direct and indirect approaches and dynamic programming to get stability guarantees, and more
- Continuous-time optimal control
    6. Indirect approach (via calculus of variations): boundary value problem, Riccati equations, LQR
    7. Indirect approach (via Pontryagin's principle of maximum): time-optimal constrained control, bang-bang control
    8. Numerical methods for both direct and indirect approaches: shooting, multiple shooting, collocation
    9. Some extensions of LQ-optimal control: stochastic LQR, LQG, LTR, $\mathcal{H}_2$
- Robust control
    10. Modeling of uncertainty, robustness analysis: small gain theorem, structured singular values
    11. Robust control design: mixed-sensitivity minimization, (general) $\mathcal{H}_\infty$-optimal control 
    12. Robust control design: loop shaping, $\mu$-synthesis
    13. Analysis of achievable performance
- Other topics
    14. Model order reduction, controller order reduction
