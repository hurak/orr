---
title: "Model predictive control (MPC)"
bibliography: 
    - "ref_mpc.bib"
    - "ref_numerical_optimal_control.bib"
format:
    html:
        html-math-method: katex
        code-fold: true
        code-summary: "Show the code"
crossref:
  fig-prefix: Fig. 
  eq-prefix: Eq.
engine: julia
---

## Deficiencies of precomputed (open-loop) optimal control

In the previous section we learnt how to compute an optimal control sequence on a finite time horizon using numerical methods for solving nonlinear programs (NLP), and quadratic programs (QP) in particular. There are two major deficiencies of such approach:

- The control sequence was computed under the assumption that the mathematical model is perfectly accurate. As soon as the reality deviates from the model, either because of some unmodelled dynamics or because of the presence of (external) disturbances, the performance of the system will deteriorate. We need a way to turn the presented open-loop (also feedforward) control scheme into a feedback one.

- The control sequence was computed for a finite time horizon. It is commonly required to consider an infinite time horizon, which is not possible with the presented approach based on solving finite-dimensional mathematical programs.

There are several ways to address these issues. Here we introduce one of them. It is known are *Model Predictive Control (MPC)*, also *Receding Horizon Control (RHC)*. Some more are presented in the next two sections (one based on indirect approach, another one based on dynamic programming).

## Model predictive control (MPC) as a way to turn open-loop control into feedback control

The idea is to compute an optimal control sequence on a finite time horizon using the optimization framework presented in the previous section, but then apply only the first element of the computed control trajectory to the system, and proceed to repeating the whole procedure after shifting the time horizon forward by one time step. The name "model predictive control" expresses the fact that a model-based prediction is the key component of the controller. This is expressed in @fig-mpc.

![Diagram describing a single MPC step. Recall that the information carried by the past input trajectories can compressed into the state of the system. A state observer providing an estimate of the state must then be a component of the whole MPC, but then needs not only the input but also the output trajectories.](figures/mpc.png){#fig-mpc}

The other name "receding horizon control" is equally descriptive, it emphasizes the phenomenon of the finite time horizon (interval, window) receding (shifting, moving, rolling) as time goes by. 

::: {.callout-note}
## We all do MPC in our everyday lives
It may take a few moments to comprehend the idea, but then it turns out perfectly natural. As a matter of fact, this is the way most of us control our lifes every day. We plan our actions on a finite time horizon, and to build this plan we use both our understanding (model) of the world and our knowledge of our current situation (state). We then execute the first action from our plan, observe the consequences of our action the and recent changes in the environment, and update our plan accordingly on a new (shifted) time horizon. We repeat this procedure over and over again. It is crucial that the prediction horizon must be long enough so that the full impact of our actions can be observed, but it must not be too long because the planning then becomes too complex and predictions unreliable. 
:::

## MPC regulation

We first investigate the situation when the reference (the set-point, the required final state) is zero. 

{{< video https://youtu.be/oMUtYZOgsng?si=cZK2RgxsjGXEQEW0 >}}

## MPC tracking

We now extend the regulation setup so that nonzero references can be tracked (followed). 

{{< video https://youtu.be/GnFaLl7qwco?si=GN79Zpddv2ZmQ4eU >}}

## Prediction horizon vs control

{{< video https://youtu.be/gMOcBSmjdkQ?si=E_Rzf341oqpeQWgm >}}

## Hard constraints vs soft constraints

Discussed in the previous video too.
